{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42800dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import os\n",
    "import sys\n",
    "import laspy\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd \n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Add parent folder to path, so that notebook can find .py scripts\n",
    "DIR_BASE = os.path.abspath(os.path.join('..'))\n",
    "if DIR_BASE not in sys.path:\n",
    "    sys.path.append(DIR_BASE)\n",
    "\n",
    "# Import functions from own .py scripts\n",
    "import config\n",
    "from pointcloud_functions import \\\n",
    "    add_geoindex_to_databases, \\\n",
    "    load_laz_pointcloud_into_database, \\\n",
    "    add_floor_points_to_points_in_gdf, \\\n",
    "    crop_and_fetch_pointclouds_per_building, \\\n",
    "    save_lidar_numpy_list\n",
    "\n",
    "from utils.utils import convert_multipoint_to_numpy, check_directory_paths, file_name_from_polygon_list\n",
    "from utils.visualization import visualize_single_3d_point_cloud\n",
    "from utils.aerial_image import get_aerial_image_lat_lon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fbb72a",
   "metadata": {},
   "source": [
    "# Configurations\n",
    "Here, we define filepaths and parameters for pointcloud creation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781f6553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pointcloud parameters\n",
    "AREA_OF_INTEREST_CODE = 'E06000014' # UK local authority boundary code to specify area of interest (AOI)\n",
    "BUILDING_BUFFER_METERS = 0.5 # buffer around building footprint in meters\n",
    "MAX_NUMBER_OF_FOOTPRINTS = None  # define how many footprints should be created. Use \"None\" to use all footprints in AOI\n",
    "POINT_COUNT_THRESHOLD = 100  # define minimum points in pointcloud, smaller pointclouds are dismissed\n",
    "NUMBER_EXAMPLE_VISUALIZATIONS = 10  # define how many example 3D plots should be created\n",
    "\n",
    "# Define project base directory and paths\n",
    "# DIR_BASE = os.getcwd() # in jupyter, use a different approach (above) to determine project DIR\n",
    "DIR_ASSETS = os.path.join(DIR_BASE, 'assets')\n",
    "DIR_OUTPUTS = os.path.join(DIR_BASE, 'outputs')\n",
    "\n",
    "DIR_LAZ_FILES = os.path.join(DIR_ASSETS, \"uk_lidar_data\")\n",
    "DIR_EPC = os.path.join(DIR_ASSETS, \"epc\")\n",
    "DIR_VISUALIZATION = os.path.join(DIR_ASSETS, \"example_pointclouds\")\n",
    "DIR_AERIAL_IMAGES = os.path.join(DIR_ASSETS, \"aerial_image_examples\")\n",
    "\n",
    "# Create a new output folder for the defined area of interest\n",
    "DIR_AOI_OUTPUT = os.path.join(DIR_OUTPUTS, AREA_OF_INTEREST_CODE)\n",
    "if os.path.isdir(DIR_AOI_OUTPUT):\n",
    "    print('output for this area of interest already exists. delete or choose other area code')\n",
    "else:\n",
    "    os.mkdir(DIR_AOI_OUTPUT)\n",
    "DIR_NPY = os.path.join(DIR_AOI_OUTPUT, 'npy_raw')\n",
    "if not os.path.isdir(DIR_NPY): os.mkdir(DIR_NPY)\n",
    "\n",
    "\n",
    "# Check that all required directories exist\n",
    "check_directory_paths([DIR_ASSETS, DIR_OUTPUTS, DIR_LAZ_FILES, DIR_VISUALIZATION, DIR_AERIAL_IMAGES, DIR_AOI_OUTPUT, DIR_NPY])\n",
    "\n",
    "DB_TABLE_NAME_LIDAR = 'uk_lidar_data'\n",
    "DB_TABLE_NAME_FOOTPRINTS = 'footprints_verisk'\n",
    "DB_TABLE_NAME_UPRN = 'uprn'\n",
    "DB_TABLE_NAME_AREA_OF_INTEREST = 'local_authority_boundaries'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71b0f1b",
   "metadata": {},
   "source": [
    "# Main\n",
    "The following code elements \n",
    "- create a database connection and test if it was successful\n",
    "- load pointcloud LAZ files into the database\n",
    "- make sure the tables in the database contain a georeference, to ensure DB query is as fast as possible\n",
    "- generate building pointclouds based by cropping points within the building's footprint\n",
    "- add a building's floorpoints artificially, because those are missing in airborne LiDAR data\n",
    "- save the pointclouds as .npy files and save required data (except LiDAR tiles) as .geojson\n",
    "- visualize a subset of the pointclouds and their arial images for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7eed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize connection to database\n",
    "db_connection_url = config.DATABASE_URL\n",
    "engine = create_engine(db_connection_url, echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece7ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test connection to database\n",
    "# with engine.connect() as con:\n",
    "#     res = con.execute('SELECT * FROM footprints_verisk LIMIT 1')\n",
    "# print(res.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04aa361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load footprint geojsons into database (only required if they haven't already been uploaded already)\n",
    "# STANDARD_CRS = 27700\n",
    "# DIR_BUILDING_FOOTPRINTS = os.path.join(DIR_ASSETS, \"aoi\")\n",
    "# gdf_footprints = load_geojson_footprints_into_database(\n",
    "#     DIR_BUILDING_FOOTPRINTS, DB_TABLE_NAME_FOOTPRINTS, engine, STANDARD_CRS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbfa9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load point cloud data into database\n",
    "# Unpacks LAZ-files and inserts all newly unpacked LAS-files into the database\n",
    "# Existing LAS-files in directory are considered to be in the database already\n",
    "load_laz_pointcloud_into_database(DIR_LAZ_FILES, DB_TABLE_NAME_LIDAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6f604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EPC data into database\n",
    "file_path = os.path.join(DIR_EPC, AREA_OF_INTEREST_CODE + '.csv')\n",
    "df_epc = pd.read_csv(file_path)\n",
    "with engine.connect() as con:\n",
    "    df_epc.to_sql('epc', con=con, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59793853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add geoindex to footprint and lidar tables and vacuum table \n",
    "db_table_names = [DB_TABLE_NAME_LIDAR, DB_TABLE_NAME_FOOTPRINTS, DB_TABLE_NAME_UPRN, DB_TABLE_NAME_AREA_OF_INTEREST]\n",
    "db_is_lidar = [1, 0, 0, 0]\n",
    "add_geoindex_to_databases(config.DATABASE_URL, db_table_names, db_is_lidar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513b10fc",
   "metadata": {},
   "source": [
    "todo: adapt SQL query to use only footprints that contain UPRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c19703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt NUMBER_OF_FOOTPRINTS to use all footprints if None\n",
    "if MAX_NUMBER_OF_FOOTPRINTS == None:\n",
    "    MAX_NUMBER_OF_FOOTPRINTS = 1000000000  # 1 billion, which is more than UKs building stock\n",
    "\n",
    "# Fetch cropped point clouds from database\n",
    "gdf = crop_and_fetch_pointclouds_per_building(\n",
    "    AREA_OF_INTEREST_CODE, BUILDING_BUFFER_METERS, MAX_NUMBER_OF_FOOTPRINTS, POINT_COUNT_THRESHOLD, engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd8df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test print some gdf entry examples (york)\n",
    "#print(gdf[gdf.id_fp==9664325]) # no uprn\n",
    "#print(gdf[gdf.id_fp==9600120]) # no pc\n",
    "#print(gdf[gdf.id_fp==9681016]) # all 3 geoms exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add floor points to building pointcloud\n",
    "gdf_pc = gdf[gdf.geom!=None]\n",
    "gdf_pc = add_floor_points_to_points_in_gdf(gdf_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b0ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw pointcloud without threshhold or scaling\n",
    "lidar_numpy_list = list(gdf_pc.geom.apply(convert_multipoint_to_numpy))\n",
    "# Save building point clouds as npy\n",
    "save_lidar_numpy_list(lidar_numpy_list, gdf_pc, DIR_NPY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97770ae7",
   "metadata": {},
   "source": [
    "# Save raw information of footprints, epc label, uprn, file mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e519c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# footprints\n",
    "gdf_footprints = gpd.GeoDataFrame({\"if_fp\": gdf.id_fp, \"geometry\": gdf.geom_fp})\n",
    "gdf_footprints = gdf_footprints.drop_duplicates()\n",
    "save_path = os.path.join(DIR_AOI_OUTPUT, str('footprints_' + AREA_OF_INTEREST_CODE + \".json\"))\n",
    "gdf_footprints.to_file(save_path, driver=\"GeoJSON\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9625d32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uprn\n",
    "gdf_uprn = gpd.GeoDataFrame({\"uprn\": gdf.uprn, \"geometry\": gdf.geom_uprn})\n",
    "gdf_uprn = gdf_uprn.drop_duplicates()\n",
    "save_path = os.path.join(DIR_AOI_OUTPUT, str('uprn_' + AREA_OF_INTEREST_CODE + \".json\"))\n",
    "gdf_uprn.to_file(save_path, driver=\"GeoJSON\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00708de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epc label\n",
    "gdf_epc = pd.DataFrame(\n",
    "    {\"id_epc_lmk_key\": gdf.id_epc_lmk_key, \n",
    "     \"rating\": gdf.energy_rating,\n",
    "     \"efficiency\": gdf.energy_efficiency}\n",
    ")\n",
    "gdf_epc = gdf_epc.drop_duplicates()\n",
    "save_path = os.path.join(DIR_AOI_OUTPUT, str('epc_' + AREA_OF_INTEREST_CODE + \".json\"))\n",
    "gdf_epc.to_json(save_path, orient='records') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b4caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label - filename mapping\n",
    "file_names = file_name_from_polygon_list(list(gdf.geom_fp), file_extension='.npy')\n",
    "gdf_mapping = pd.DataFrame(\n",
    "    {\"id_fp\": gdf.id_fp,\n",
    "     \"uprn\": gdf.uprn,\n",
    "     \"id_id_epc_lmk_key\": gdf.id_epc_lmk_key,\n",
    "     \"id_query\": gdf.id_query,\n",
    "     \"epc_rating\": gdf.energy_rating,\n",
    "     \"epc_efficiency\": gdf.energy_efficiency,\n",
    "     \"file_name\": file_names\n",
    "    } \n",
    ")\n",
    "save_path = os.path.join(DIR_AOI_OUTPUT, str('label_filename_mapping_' + AREA_OF_INTEREST_CODE + \".json\"))\n",
    "gdf_mapping.to_json(save_path, orient='index') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ceb121",
   "metadata": {},
   "source": [
    "# Visualization for evaliation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35029b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize example building pointcloud data \n",
    "for i, lidar_pc in enumerate(lidar_numpy_list):\n",
    "    if i <= NUMBER_EXAMPLE_VISUALIZATIONS:\n",
    "        pce_file_name = file_name_from_polygon_list(list(gdf.iloc[i].geom_fp), file_extension=\".html\")\n",
    "        save_path = os.path.join(DIR_VISUALIZATION, pce_file_name)\n",
    "        visualize_single_3d_point_cloud(\n",
    "            lidar_pc,\n",
    "            title=str(i),\n",
    "            save_path=save_path,\n",
    "            show=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download aerial image for the building examples\n",
    "gdf_lat_lon = gdf.to_crs(4326)\n",
    "\n",
    "for i, building in enumerate(gdf_lat_lon.iloc):\n",
    "    img_filename = file_name_from_polygon_list(list(gdf.iloc[i].geom_fp), file_extension=\".png\")\n",
    "    if i <= NUMBER_EXAMPLE_VISUALIZATIONS:\n",
    "        cp = building.geom.centroid\n",
    "        get_aerial_image_lat_lon(\n",
    "            latitude=cp.y,\n",
    "            longitude=cp.x,\n",
    "            image_name=img_filename,\n",
    "            horizontal_px=512,\n",
    "            vertical_px=512,\n",
    "            scale=1,\n",
    "            zoom=21,\n",
    "            save_directory=DIR_AERIAL_IMAGES\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981ac3fe",
   "metadata": {},
   "source": [
    "# ARCHIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddbbe8f",
   "metadata": {},
   "source": [
    "### Raw code of LAZ to DB for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f5c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive: are you sure you want to run this?\n",
    "    \n",
    "# get files in directory\n",
    "files_uk_lidar = os.listdir(DIR_LAZ_FILES)\n",
    "\n",
    "# check which laz files have not yet been unpacked\n",
    "laz_files = [file for file in files_uk_lidar if file[-4:] == \".laz\"]\n",
    "las_files = [file for file in files_uk_lidar if file[-4:] == \".las\"]\n",
    "unpacked_files = [laz_file for laz_file in laz_files if not laz_file[:-4] + '.las' in las_files]\n",
    "#unpacked_files = laz_files\n",
    "import pdal\n",
    "import json\n",
    "\n",
    "print('Loading pointcloud data from las to database. This process can take several minutes')\n",
    "# unzip LAZ files, if corresponding LAS file does not exist\n",
    "for i, unpacked_file in enumerate(unpacked_files):\n",
    "    print('unpacking laz file %s of %s: %s' % (str(i + 1), str(len(unpacked_files)), unpacked_file))\n",
    "    # unzip laz to las\n",
    "    in_laz = os.path.join(DIR_LAZ_FILES, unpacked_file)\n",
    "    #out_las = os.path.join(DIR_LAZ_FILES, unpacked_file)\n",
    "    out_las = os.path.join(DIR_LAZ_FILES, unpacked_file[:-4] + '.las')\n",
    "    las = laspy.read(in_laz)\n",
    "    las = laspy.convert(las)\n",
    "    print('converted laz to las')\n",
    "    las.write(out_las)\n",
    "    # load las files into database\n",
    "    print('loading files into database')\n",
    "    las_to_db_pipeline = {\n",
    "        \"pipeline\": [\n",
    "            {\n",
    "                \"type\": \"readers.las\",\n",
    "                \"filename\": out_las,\n",
    "                \"spatialreference\": \"EPSG:27700\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.chipper\",\n",
    "                \"capacity\": 800\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"writers.pgpointcloud\",\n",
    "                \"connection\": \"host='%s' dbname='%s' user='%s' password='%s' port='%s'\" %\n",
    "                              (config.POSTGRES_HOST, config.POSTGRES_DATABASE,\n",
    "                               config.POSTGRES_USER, config.POSTGRES_PASSWORD,\n",
    "                               config.POSTGRES_PORT),\n",
    "                \"schema\": \"public\",\n",
    "                \"table\": DB_TABLE_NAME_LIDAR,\n",
    "                \"compression\": \"dimensional\",\n",
    "                \"srid\": \"27700\",\n",
    "                \"overwrite\": \"false\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    print('loading laz file %s of %s into database' % (str(i + 1), str(len(unpacked_files))))\n",
    "    pipeline = pdal.Pipeline(json.dumps(las_to_db_pipeline))\n",
    "    pipeline.execute()\n",
    "\n",
    "print('Loading data into database finished')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
