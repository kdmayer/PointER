{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42800dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Import python packages\n",
    "import sys\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Add parent folder to path, so that notebook can find .py scripts\n",
    "DIR_BASE = os.path.abspath('..')\n",
    "if DIR_BASE not in sys.path:\n",
    "    sys.path.append(DIR_BASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f522cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions from own .py scripts\n",
    "from src.pointcloud_functions import *\n",
    "from utils.utils import convert_multipoint_to_numpy, check_directory_paths, file_name_from_polygon_list\n",
    "from utils.visualization import batch_visualization\n",
    "from utils.aerial_image import get_aerial_image_lat_lon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fbb72a",
   "metadata": {},
   "source": [
    "# Configurations\n",
    "Here, we define filepaths and parameters for pointcloud creation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781f6553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UK local authority boundary code to specify area of interest (AOI)\n",
    "AREA_OF_INTEREST_CODE = 'E06000014'\n",
    "# create results for publishing or not (due to license) - if False: results contain verisk footprints & epc addresses\n",
    "RESULTS_PUBLIC = False\n",
    "# buffer around building footprint in meters\n",
    "BUILDING_BUFFER_METERS = 0.5\n",
    "# define how many footprints should be created. Use \"None\" to use all footprints in AOI\n",
    "MAX_NUMBER_OF_FOOTPRINTS = None\n",
    "# number of footprints per query (size of data requires processing in chunks)\n",
    "NUM_FOOTPRINTS_CHUNK_SIZE = 500\n",
    "# define minimum points in point cloud, smaller point clouds are dismissed\n",
    "POINT_COUNT_THRESHOLD = 100\n",
    "# define how many example 3D plots should be created\n",
    "NUMBER_EXAMPLE_VISUALIZATIONS = 20\n",
    "# define if google aerial images should be downloaded for evaluation purposes.\n",
    "# Make sure to add a google key in the config file if this is set to True!\n",
    "ENABLE_AERIAL_IMAGE_DOWNLOAD = False\n",
    "# Enable starting from a specific iteration.\n",
    "# Default: 0. Only adapt if necessary! (e.g. to continue an interrupted run)\n",
    "START_ITERATION = 0\n",
    "\n",
    "# Define project base directory and paths\n",
    "DIR_ASSETS = os.path.join(DIR_BASE, 'assets')\n",
    "DIR_LAZ_FILES = os.path.join(DIR_ASSETS, \"uk_lidar_data\")\n",
    "DIR_EPC = os.path.join(DIR_ASSETS, \"epc\")\n",
    "DIR_VISUALIZATION = os.path.join(DIR_ASSETS, \"example_pointclouds\")\n",
    "DIR_AERIAL_IMAGES = os.path.join(DIR_ASSETS, \"aerial_image_examples\")\n",
    "\n",
    "# Create a new output folder for the defined area of interest\n",
    "DIR_OUTPUTS = os.path.join('/home/vagrant/data_share', 'outputs')\n",
    "SUB_FOLDER_LIST = ['npy_raw', 'footprints', 'uprn', 'epc', 'filename_mapping']\n",
    "DIR_AOI_OUTPUT = output_folder_setup(DIR_OUTPUTS, AREA_OF_INTEREST_CODE, SUB_FOLDER_LIST)\n",
    "\n",
    "# Check that all required directories exist\n",
    "check_directory_paths([DIR_ASSETS, DIR_OUTPUTS, DIR_LAZ_FILES, DIR_VISUALIZATION, DIR_AERIAL_IMAGES, DIR_AOI_OUTPUT])\n",
    "\n",
    "# Define database table names\n",
    "DB_TABLE_NAME_LIDAR = 'uk_lidar_data'\n",
    "DB_TABLE_NAME_FOOTPRINTS = 'footprints_verisk'\n",
    "DB_TABLE_NAME_UPRN = 'uprn'\n",
    "DB_TABLE_NAME_EPC = 'epc'\n",
    "DB_TABLE_NAME_AREA_OF_INTEREST = 'local_authority_boundaries'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71b0f1b",
   "metadata": {},
   "source": [
    "# Main\n",
    "The following code elements \n",
    "- create a database connection and test if it was successful\n",
    "- load pointcloud LAZ files into the database\n",
    "- make sure the tables in the database contain a georeference, to ensure DB query is as fast as possible\n",
    "- generate building pointclouds based by cropping points within the building's footprint\n",
    "- add a building's floorpoints artificially, because those are missing in airborne LiDAR data\n",
    "- save the pointclouds as .npy files and save required data (except LiDAR tiles) as .geojson\n",
    "- visualize a subset of the pointclouds and their arial images for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7eed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize connection to database\n",
    "DB_CONNECTION_URL = config.DATABASE_URL\n",
    "engine = create_engine(DB_CONNECTION_URL, echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece7ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test connection to database\n",
    "with engine.connect() as con:\n",
    "    res = con.execute('SELECT * FROM footprints_verisk LIMIT 1')\n",
    "print(res.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04aa361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load footprint geojsons into database (only required if they haven't already been uploaded already)\n",
    "# STANDARD_CRS = 27700\n",
    "# DIR_BUILDING_FOOTPRINTS = os.path.join(DIR_ASSETS, \"aoi\")\n",
    "# gdf_footprints = load_geojson_footprints_into_database(\n",
    "#     DIR_BUILDING_FOOTPRINTS, DB_TABLE_NAME_FOOTPRINTS, engine, STANDARD_CRS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbfa9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load point cloud data into database\n",
    "# Unpacks LAZ-files and inserts all newly unpacked LAS-files into the database\n",
    "# Existing LAS-files in directory are considered to be in the database already\n",
    "print(\"Starting LAZ to DB\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "load_laz_pointcloud_into_database(DIR_LAZ_FILES, DB_TABLE_NAME_LIDAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6f604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load EPC data into database\n",
    "file_path = os.path.join(DIR_EPC, AREA_OF_INTEREST_CODE + '.csv')\n",
    "df_epc = pd.read_csv(file_path)\n",
    "with engine.connect() as con:\n",
    "    df_epc.to_sql('epc', con=con, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59793853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add geoindex to footprint and lidar tables and vacuum table\n",
    "print(\"Starting geoindexing\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "db_table_names = [DB_TABLE_NAME_LIDAR, DB_TABLE_NAME_FOOTPRINTS, DB_TABLE_NAME_UPRN, DB_TABLE_NAME_AREA_OF_INTEREST]\n",
    "db_is_lidar = [1, 0, 0, 0]\n",
    "add_geoindex_to_databases(config.DATABASE_URL, db_table_names, db_is_lidar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c19703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt NUMBER_OF_FOOTPRINTS to use all footprints if None\n",
    "if MAX_NUMBER_OF_FOOTPRINTS == None:\n",
    "    MAX_NUMBER_OF_FOOTPRINTS = 1000000000  # 1 billion, which is more than UKs building stock\n",
    "# Create materialized view of footprints in area of interest (required for processing in chunks)\n",
    "num_footprints = create_footprints_in_area_materialized_view(\n",
    "    DB_CONNECTION_URL, AREA_OF_INTEREST_CODE, MAX_NUMBER_OF_FOOTPRINTS, DB_TABLE_NAME_AREA_OF_INTEREST,\n",
    "    DB_TABLE_NAME_FOOTPRINTS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd8df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting point cloud cropping\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "# processing the cropping in chunks\n",
    "num_iterations = np.ceil(num_footprints / NUM_FOOTPRINTS_CHUNK_SIZE)\n",
    "# initialize loop's variables, because they are deleted at beginning of every loop to avoid memory overflow\n",
    "gdf = gpd.GeoDataFrame()\n",
    "gdf_pc = gpd.GeoDataFrame()\n",
    "lidar_numpy_list = []\n",
    "for n_iteration in np.arange(START_ITERATION, num_iterations):\n",
    "    # delete gdf manually to avoid memory overflow\n",
    "    del gdf, gdf_pc, lidar_numpy_list\n",
    "\n",
    "    print(\"Prcoessing footprints - chunk %s out of %s - \" % (n_iteration, num_iterations),\n",
    "          datetime.now().strftime(\"%H:%M:%S\"))\n",
    "    fp_num_start = n_iteration * NUM_FOOTPRINTS_CHUNK_SIZE\n",
    "    fp_num_end = (n_iteration + 1) * NUM_FOOTPRINTS_CHUNK_SIZE\n",
    "\n",
    "    # Fetch cropped point clouds from database\n",
    "    gdf = crop_and_fetch_pointclouds_per_building(\n",
    "        fp_num_start, fp_num_end, AREA_OF_INTEREST_CODE, BUILDING_BUFFER_METERS, MAX_NUMBER_OF_FOOTPRINTS,\n",
    "        POINT_COUNT_THRESHOLD, DB_TABLE_NAME_UPRN, DB_TABLE_NAME_EPC, DB_TABLE_NAME_LIDAR, engine\n",
    "    )\n",
    "    # Add floor points to building pointcloud\n",
    "    print(\"Floor point adding - chunk %s out of %s - \" % (n_iteration, num_iterations),\n",
    "          datetime.now().strftime(\"%H:%M:%S\"))\n",
    "    gdf_pc = gdf[gdf.geom != None].copy()\n",
    "    gdf_pc = add_floor_points_to_points_in_gdf(gdf_pc)\n",
    "\n",
    "    # Save raw point cloud without threshold or scaling\n",
    "    print(\"Numpy list creation - chunk %s out of %s - \" % (n_iteration, num_iterations),\n",
    "          datetime.now().strftime(\"%H:%M:%S\"))\n",
    "    lidar_numpy_list = list(gdf_pc.geom.apply(convert_multipoint_to_numpy))\n",
    "    # Save building point clouds as npy\n",
    "    print(\"Numpy saving - chunk %s out of %s - \" % (n_iteration, num_iterations), datetime.now().strftime(\"%H:%M:%S\"))\n",
    "    dir_npy = os.path.join(DIR_AOI_OUTPUT, 'npy_raw')\n",
    "    save_lidar_numpy_list(lidar_numpy_list, gdf_pc, dir_npy)\n",
    "\n",
    "    # Save raw information of footprints, epc label, uprn, file mapping\n",
    "    print(\"Save additional data - chunk %s out of %s - \" % (n_iteration, num_iterations),\n",
    "          datetime.now().strftime(\"%H:%M:%S\"))\n",
    "    save_raw_input_information(n_iteration, gdf, DIR_AOI_OUTPUT, AREA_OF_INTEREST_CODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stitch all raw input information jsons to create one result json\n",
    "stitch_raw_input_information(DIR_OUTPUTS, AREA_OF_INTEREST_CODE, SUB_FOLDER_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b0ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate simple production metrics for point cloud production in area of interest\n",
    "file_path = os.path.join(DIR_AOI_OUTPUT, str('filename_mapping_' + str(AREA_OF_INTEREST_CODE) + '.json'))\n",
    "# load mapping GeoDataframe\n",
    "gdf_fm = case_specific_json_loader(file_path, 'filename_mapping')\n",
    "# calculate metrics\n",
    "production_metrics_simple(gdf_fm, DIR_AOI_OUTPUT, AREA_OF_INTEREST_CODE)\n",
    "# create final result geojson (can take a while)\n",
    "print(\"Creating final result .geojson - this can process can take some minutes\")\n",
    "generate_final_geojson(DIR_EPC, DIR_OUTPUTS, AREA_OF_INTEREST_CODE, gdf_fm, is_public=RESULTS_PUBLIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ceb121",
   "metadata": {},
   "source": [
    "# Visualization for evaluation of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138f9b35",
   "metadata": {},
   "source": [
    "### Code below does not run nor produce visible output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35029b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize example building point cloud data\n",
    "DIR_POINT_CLOUDS = os.path.join(DIR_OUTPUTS, AREA_OF_INTEREST_CODE, SUB_FOLDER_LIST[0])\n",
    "batch_visualization(DIR_POINT_CLOUDS, DIR_VISUALIZATION,\n",
    "                    format='html', status_update=False, number_examples=NUMBER_EXAMPLE_VISUALIZATIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download aerial image for the building examples\n",
    "if ENABLE_AERIAL_IMAGE_DOWNLOAD:\n",
    "    pc_file_names = os.listdir(DIR_POINT_CLOUDS)\n",
    "    pc_file_names = pc_file_names[:NUMBER_EXAMPLE_VISUALIZATIONS]\n",
    "    pc_file_names = [fn[:-4] for fn in pc_file_names]\n",
    "    center_point_list = [Point(float(fn[0:fn.find(\"_\"):]), float(fn[fn.find(\"_\") + 1:])) for fn in pc_file_names]\n",
    "\n",
    "    gdf_center_points_lat_lon = gpd.GeoDataFrame(\n",
    "        {\"geometry\": center_point_list}\n",
    "    )\n",
    "    gdf_center_points_lat_lon.crs = 27700\n",
    "    gdf_center_points_lat_lon = gdf_center_points_lat_lon.to_crs(4326)\n",
    "\n",
    "    img_filenames = [fn + '.png' for fn in pc_file_names]\n",
    "\n",
    "    for i, building in enumerate(gdf_center_points_lat_lon.iloc):\n",
    "        if i <= NUMBER_EXAMPLE_VISUALIZATIONS:\n",
    "            cp = building.geometry\n",
    "            get_aerial_image_lat_lon(\n",
    "                latitude=cp.y,\n",
    "                longitude=cp.x,\n",
    "                image_name=img_filenames[i],\n",
    "                horizontal_px=512,\n",
    "                vertical_px=512,\n",
    "                scale=1,\n",
    "                zoom=21,\n",
    "                save_directory=DIR_AERIAL_IMAGES\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
