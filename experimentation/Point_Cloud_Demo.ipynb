{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38578e35",
   "metadata": {},
   "source": [
    "### Helpful links:\n",
    "\n",
    "### Point Cloud Processing:\n",
    "\n",
    "- https://github.com/szenergy/awesome-lidar\n",
    "- https://github.com/PointCloudLibrary/pcl\n",
    "- https://github.com/daavoo/pyntcloud\n",
    "- https://github.com/isl-org/Open3D\n",
    "- https://pdal.io/stages/filters.html\n",
    "- https://www.danielgm.net/cc/\n",
    "\n",
    "### Visualization:\n",
    "\n",
    "- https://deck.gl/\n",
    "- https://kepler.gl/\n",
    "- https://plas.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1160d934",
   "metadata": {},
   "source": [
    "## To Do:\n",
    "\n",
    "1. Think about folder structure and file names for processing many tiles consecutively \n",
    "2. Normalize LiDAR point clouds and save them as .npy format (scaling must be relative to the height of the tallest building)\n",
    "3. Enrich point clouds with street view/aerial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b48861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "from typing import List\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pdal\n",
    "import shapely\n",
    "import json\n",
    "import laspy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%cd assets\n",
    "assert os.getcwd() == '/Users/kevin/Projects/CS224W_LIDAR/assets', \"You are not in the assets DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce591d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "POINT_COUNT_THRESHOLD = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_3d_array(point_cloud_array: np.ndarray=None, file_name_list: List=None, example_ID=None):\n",
    "    \n",
    "    x = point_cloud_array[example_ID, :, 0].flatten()\n",
    "    y = point_cloud_array[example_ID, :, 1].flatten()\n",
    "    z = point_cloud_array[example_ID, :, 2].flatten()\n",
    "\n",
    "    scatter = go.Scatter3d(x=x, y=y, z=z, mode='markers', \n",
    "                         marker=dict(size = 3, color = z, colorscale = 'Viridis'))\n",
    "    layout = go.Layout(title = f'Visualization of {file_name_list[example_ID]}')\n",
    "    fig = go.Figure(data = [scatter], layout = layout)\n",
    "    fig.show()\n",
    "\n",
    "def _convert_numpy_to_las(x: np.ndarray=None, header=None):\n",
    "    \n",
    "    outfile = laspy.LasData(header)\n",
    "    outfile.x = x[:,0]\n",
    "    outfile.y = x[:,1]\n",
    "    outfile.z = x[:,2]\n",
    "    outfile.intensity = x[:,3]\n",
    "    outfile.raw_classification = x[:,4]\n",
    "    outfile.scan_angle_rank = x[:,5]\n",
    "    \n",
    "    return outfile\n",
    "\n",
    "def _sample_random_points(x: np.ndarray=None, subset_size: int=None):\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    lidar_subset = rng.choice(a=x, size=subset_size, replace=False, axis=0)\n",
    "    \n",
    "    return lidar_subset\n",
    "\n",
    "def _convert_las_to_numpy(las_data = None):\n",
    "    \n",
    "    lidar_numpy = np.array((las_data.x, \n",
    "                             las_data.y, \n",
    "                             las_data.z, \n",
    "                             las_data.intensity, \n",
    "                             las_data.raw_classification, \n",
    "                             las_data.scan_angle_rank)).transpose()\n",
    "    \n",
    "    return lidar_numpy\n",
    "        \n",
    "def subsample_las(original_las_data_filepath: str=None, subset_size: int=1000000):\n",
    "\n",
    "    org_las_data = laspy.read(original_las_data_filepath)\n",
    "    # Set meta data for new LAS file based on settings from original LAS file\n",
    "    hdr = org_las_data.header\n",
    "    hdr.point_count = 0\n",
    "    \n",
    "    lidar_ndarray = _convert_las_to_numpy(las_data = org_las_data)\n",
    "    print(f\"SHAPE of LIDAR: {lidar_ndarray.shape}\")\n",
    "    \n",
    "    lidar_subset = _sample_random_points(x=lidar_ndarray, subset_size=subset_size)\n",
    "    print(f\"SHAPE of LIDAR_SUBSET: {lidar_subset.shape}\")\n",
    "    \n",
    "    outfile = _convert_numpy_to_las(lidar_subset, hdr)\n",
    "    output_filepath = original_las_data_filepath[:-4] + \"_SUBSET.las\"\n",
    "    \n",
    "    print(f\"Saving subsampled LAS file to: {output_filepath}\")\n",
    "    outfile.write(output_filepath)\n",
    "    \n",
    "    return outfile\n",
    "\n",
    "def create_tile_bounding_box(original_las_data_filepath: str=None):\n",
    "    \n",
    "    las_data = laspy.read(original_las_data_filepath)\n",
    "    min_x, min_y, min_z, max_x, max_y, max_z = [*las_data.header.min, *las_data.header.max]\n",
    "    return box(minx=min_x, miny=min_y, maxx=max_x, maxy=max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = subsample_las(\"SP3278_P_11321_20171123_20171123.las\")\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3422b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_footprints = gpd.read_file(\"coventry_building_footprints.geojson\")\n",
    "\n",
    "# Buffer polygons a bit to capture the building footprint better\n",
    "osm_footprints[\"geometry\"] = osm_footprints[\"geometry\"].buffer(1)\n",
    "\n",
    "# Reproject OSM footprints to EPSG:27700, if necessary\n",
    "#osm_footprints = osm_footprints.to_crs(\"EPSG:27700\")\n",
    "#osm_footprints.to_file(\"coventry_building_footprints.geojson\", driver='GeoJSON')\n",
    "\n",
    "footprint_list = osm_footprints['geometry'].tolist()\n",
    "\n",
    "# Select only polygons which are within the LiDAR tile and save their WKT string\n",
    "lidar_bounding_box = create_tile_bounding_box(\"SP3278_P_11321_20171123_20171123.las\")\n",
    "polys = [elem.wkt for elem in footprint_list if isinstance(elem, shapely.geometry.polygon.Polygon) and lidar_bounding_box.contains(elem.centroid)]\n",
    "print(f\"Number of relevant polygons: {len(polys)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29dde0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a subset of the footprint polygons for debugging purposes\n",
    "polys = random.sample(polys, 50)\n",
    "\n",
    "for idx, polygon in enumerate(polys):\n",
    "    \n",
    "    pipeline_definition = {\n",
    "\n",
    "        'pipeline': [\n",
    "\n",
    "        \"SP3278_P_11321_20171123_20171123.las\",\n",
    "\n",
    "        {\n",
    "            \"type\":\"filters.crop\",\n",
    "            \"polygon\":polygon\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"type\":\"writers.las\",\n",
    "            \"filename\":f\"cropped_{idx}.las\"\n",
    "        }\n",
    "\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    pipeline = pdal.Pipeline(json.dumps(pipeline_definition))\n",
    "\n",
    "    pipeline.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud_examples = []\n",
    "point_cloud_filenames = []\n",
    "\n",
    "for file_path in os.listdir(os.getcwd()):\n",
    "    \n",
    "    # All PDAL-based output files start with \"cropped\"\n",
    "    if file_path.startswith(\"cropped\"):\n",
    "    \n",
    "        las_point_cloud = laspy.read(file_path)\n",
    "        point_count = len(las_point_cloud.points)\n",
    "\n",
    "        if point_count < POINT_COUNT_THRESHOLD:\n",
    "            os.remove(file_path)\n",
    "\n",
    "        else:\n",
    "\n",
    "            numpy_point_cloud = _convert_las_to_numpy(las_point_cloud)\n",
    "            numpy_point_cloud = _sample_random_points(x=numpy_point_cloud, subset_size=POINT_COUNT_THRESHOLD)\n",
    "            numpy_point_cloud = numpy_point_cloud[np.newaxis, ...]\n",
    "\n",
    "            point_cloud_examples.append(numpy_point_cloud)\n",
    "            point_cloud_filenames.append(file_path)\n",
    "\n",
    "point_cloud_examples = np.concatenate(point_cloud_examples, axis=0)\n",
    "point_cloud_examples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085a8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_3d_array(point_cloud_examples, point_cloud_filenames, example_ID=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8061475d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
