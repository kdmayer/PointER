{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38578e35",
   "metadata": {},
   "source": [
    "### Helpful links:\n",
    "\n",
    "### Point Cloud Processing:\n",
    "\n",
    "- https://github.com/szenergy/awesome-lidar\n",
    "- https://github.com/PointCloudLibrary/pcl\n",
    "- https://github.com/daavoo/pyntcloud\n",
    "- https://github.com/isl-org/Open3D\n",
    "- https://pdal.io/stages/filters.html\n",
    "- https://www.danielgm.net/cc/\n",
    "\n",
    "### Visualization:\n",
    "\n",
    "- https://deck.gl/\n",
    "- https://kepler.gl/\n",
    "- https://plas.io/\n",
    "\n",
    "### LiDAR data source:\n",
    "\n",
    "- https://www.data.gov.uk/dataset/f0db0249-f17b-4036-9e65-309148c97ce4/national-lidar-programme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b48861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pdal\n",
    "import shapely\n",
    "import json\n",
    "import laspy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%cd assets\n",
    "assert os.getcwd().split(\"/\")[-1] == 'assets', \"You are not in the assets directory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce591d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "LAS_FILE_NAME = \"SP3278_P_11321_20171123_20171123.las\"\n",
    "POINT_COUNT_THRESHOLD = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pdal_pipeline(footprint_list: List=None, las_file_path: str=None, random_sample_size: int=None):\n",
    "    \n",
    "    if random_sample_size == None:\n",
    "        footprint_list = footprint_list\n",
    "    else: \n",
    "        # Sample a subset of the footprint polygons for debugging purposes\n",
    "        footprint_list = random.sample(footprint_list, random_sample_size)\n",
    "        \n",
    "    for i in tqdm(range(len(footprint_list))):\n",
    "        \n",
    "        pipeline_definition = {\n",
    "\n",
    "            'pipeline': [\n",
    "            las_file_path,\n",
    "            {\n",
    "                \"type\":\"filters.crop\",\n",
    "                \"polygon\":footprint_list[i]\n",
    "            },\n",
    "            {\n",
    "                \"type\":\"writers.las\",\n",
    "                \"filename\":f\"cropped_{i}.las\"\n",
    "            }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        pipeline = pdal.Pipeline(json.dumps(pipeline_definition))\n",
    "        pipeline.execute()\n",
    "    \n",
    "def visualize_3d_array(point_cloud_array: np.ndarray=None, file_name_list: List=None, example_ID=None):\n",
    "    \n",
    "    x = point_cloud_array[example_ID, :, 0].flatten()\n",
    "    y = point_cloud_array[example_ID, :, 1].flatten()\n",
    "    z = point_cloud_array[example_ID, :, 2].flatten()\n",
    "\n",
    "    scatter = go.Scatter3d(x=x, y=y, z=z, mode='markers', \n",
    "                         marker=dict(size = 3, color = z, colorscale = 'Viridis'))\n",
    "    layout = go.Layout(title = f'Visualization of {file_name_list[example_ID]}')\n",
    "    fig = go.Figure(data = [scatter], layout = layout)\n",
    "    fig.show()\n",
    "\n",
    "def _convert_numpy_to_las(x: np.ndarray=None, header=None):\n",
    "    \n",
    "    outfile = laspy.LasData(header)\n",
    "    outfile.x = x[:,0]\n",
    "    outfile.y = x[:,1]\n",
    "    outfile.z = x[:,2]\n",
    "    outfile.intensity = x[:,3]\n",
    "    outfile.raw_classification = x[:,4]\n",
    "    outfile.scan_angle_rank = x[:,5]\n",
    "    \n",
    "    return outfile\n",
    "\n",
    "def _sample_random_points(x: np.ndarray=None, random_sample_size: int=None):\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    lidar_subset = rng.choice(a=x, size=random_sample_size, replace=False, axis=0)\n",
    "    \n",
    "    return lidar_subset\n",
    "\n",
    "def _convert_las_to_numpy(las_data = None):\n",
    "    \n",
    "    lidar_numpy = np.array((las_data.x, \n",
    "                             las_data.y, \n",
    "                             las_data.z, \n",
    "                             las_data.intensity, \n",
    "                             las_data.raw_classification, \n",
    "                             las_data.scan_angle_rank)).transpose()\n",
    "    \n",
    "    return lidar_numpy\n",
    "        \n",
    "def subsample_las(original_las_data_filepath: str=None, random_sample_size: int=1000000):\n",
    "\n",
    "    org_las_data = laspy.read(original_las_data_filepath)\n",
    "    # Set meta data for new LAS file based on settings from original LAS file\n",
    "    hdr = org_las_data.header\n",
    "    hdr.point_count = 0\n",
    "    \n",
    "    lidar_ndarray = _convert_las_to_numpy(las_data = org_las_data)\n",
    "    print(f\"SHAPE of LIDAR: {lidar_ndarray.shape}\")\n",
    "    \n",
    "    lidar_subset = _sample_random_points(x=lidar_ndarray, random_sample_size=random_sample_size)\n",
    "    print(f\"SHAPE of LIDAR_SUBSET: {lidar_subset.shape}\")\n",
    "    \n",
    "    outfile = _convert_numpy_to_las(lidar_subset, hdr)\n",
    "    output_filepath = original_las_data_filepath[:-4] + \"_SUBSET.las\"\n",
    "    \n",
    "    print(f\"Saving subsampled LAS file to: {output_filepath}\")\n",
    "    outfile.write(output_filepath)\n",
    "    \n",
    "    return outfile\n",
    "\n",
    "def create_tile_bounding_box(original_las_data_filepath: str=None):\n",
    "    \n",
    "    las_data = laspy.read(original_las_data_filepath)\n",
    "    min_x, min_y, min_z, max_x, max_y, max_z = [*las_data.header.min, *las_data.header.max]\n",
    "    return box(minx=min_x, miny=min_y, maxx=max_x, maxy=max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = subsample_las(LAS_FILE_NAME)\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3422b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_footprints = gpd.read_file(\"coventry_building_footprints.geojson\")\n",
    "\n",
    "# Buffer polygons a bit to capture the building footprint better\n",
    "osm_footprints[\"geometry\"] = osm_footprints[\"geometry\"].buffer(1)\n",
    "\n",
    "# Reproject OSM footprints to EPSG:27700, if necessary\n",
    "#osm_footprints = osm_footprints.to_crs(\"EPSG:27700\")\n",
    "#osm_footprints.to_file(\"coventry_building_footprints.geojson\", driver='GeoJSON')\n",
    "\n",
    "footprint_list = osm_footprints['geometry'].tolist()\n",
    "\n",
    "# Select only polygons which are within the LiDAR tile and save their WKT string\n",
    "lidar_bounding_box = create_tile_bounding_box(LAS_FILE_NAME)\n",
    "polys = [elem.wkt for elem in footprint_list if isinstance(elem, shapely.geometry.polygon.Polygon) and lidar_bounding_box.contains(elem.centroid)]\n",
    "print(f\"Number of relevant polygons: {len(polys)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29dde0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pdal_pipeline(footprint_list=polys, las_file_path=LAS_FILE_NAME, random_sample_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud_examples = []\n",
    "point_cloud_filenames = []\n",
    "\n",
    "for file_path in os.listdir(os.getcwd()):\n",
    "    \n",
    "    # All PDAL-based output files start with \"cropped\"\n",
    "    if file_path.startswith(\"cropped\"):\n",
    "    \n",
    "        las_point_cloud = laspy.read(file_path)\n",
    "        point_count = len(las_point_cloud.points)\n",
    "\n",
    "        if point_count < POINT_COUNT_THRESHOLD:\n",
    "            os.remove(file_path)\n",
    "\n",
    "        else:\n",
    "\n",
    "            numpy_point_cloud = _convert_las_to_numpy(las_point_cloud)\n",
    "            numpy_point_cloud = _sample_random_points(x=numpy_point_cloud, subset_size=POINT_COUNT_THRESHOLD)\n",
    "            numpy_point_cloud = numpy_point_cloud[np.newaxis, ...]\n",
    "\n",
    "            point_cloud_examples.append(numpy_point_cloud)\n",
    "            point_cloud_filenames.append(file_path)\n",
    "\n",
    "point_cloud_examples = np.concatenate(point_cloud_examples, axis=0)\n",
    "point_cloud_examples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085a8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_3d_array(point_cloud_examples, point_cloud_filenames, example_ID=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8061475d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
